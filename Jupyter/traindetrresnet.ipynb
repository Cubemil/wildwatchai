{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-06-27T20:52:50.484942Z",
     "start_time": "2024-06-27T20:52:44.652476Z"
    }
   },
   "source": [
    "!pip install supervision\n",
    "!pip install torch\n",
    "!pip install -i https://test.pypi.org/simple/ supervision==0.3.0\n",
    "!pip install -q transformers\n",
    "!pip install -q pytorch-lightning\n",
    "!pip install -q roboflow\n",
    "!pip install -q timm\n",
    "!pip install pycocotools\n",
    "!\n",
    "\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: supervision in ./.venv/lib/python3.9/site-packages (0.21.0)\r\n",
      "Requirement already satisfied: defusedxml<0.8.0,>=0.7.1 in ./.venv/lib/python3.9/site-packages (from supervision) (0.7.1)\r\n",
      "Requirement already satisfied: matplotlib>=3.6.0 in ./.venv/lib/python3.9/site-packages (from supervision) (3.9.0)\r\n",
      "Requirement already satisfied: numpy>=1.21.2 in ./.venv/lib/python3.9/site-packages (from supervision) (1.26.4)\r\n",
      "Requirement already satisfied: opencv-python-headless>=4.5.5.64 in ./.venv/lib/python3.9/site-packages (from supervision) (4.10.0.84)\r\n",
      "Requirement already satisfied: pillow>=9.4 in ./.venv/lib/python3.9/site-packages (from supervision) (10.3.0)\r\n",
      "Requirement already satisfied: pyyaml>=5.3 in ./.venv/lib/python3.9/site-packages (from supervision) (6.0.1)\r\n",
      "Requirement already satisfied: scipy<2.0.0,>=1.10.0 in ./.venv/lib/python3.9/site-packages (from supervision) (1.13.1)\r\n",
      "Requirement already satisfied: contourpy>=1.0.1 in ./.venv/lib/python3.9/site-packages (from matplotlib>=3.6.0->supervision) (1.2.1)\r\n",
      "Requirement already satisfied: cycler>=0.10 in ./.venv/lib/python3.9/site-packages (from matplotlib>=3.6.0->supervision) (0.12.1)\r\n",
      "Requirement already satisfied: fonttools>=4.22.0 in ./.venv/lib/python3.9/site-packages (from matplotlib>=3.6.0->supervision) (4.53.0)\r\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in ./.venv/lib/python3.9/site-packages (from matplotlib>=3.6.0->supervision) (1.4.5)\r\n",
      "Requirement already satisfied: packaging>=20.0 in ./.venv/lib/python3.9/site-packages (from matplotlib>=3.6.0->supervision) (24.1)\r\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in ./.venv/lib/python3.9/site-packages (from matplotlib>=3.6.0->supervision) (3.1.2)\r\n",
      "Requirement already satisfied: python-dateutil>=2.7 in ./.venv/lib/python3.9/site-packages (from matplotlib>=3.6.0->supervision) (2.9.0.post0)\r\n",
      "Requirement already satisfied: importlib-resources>=3.2.0 in ./.venv/lib/python3.9/site-packages (from matplotlib>=3.6.0->supervision) (6.4.0)\r\n",
      "Requirement already satisfied: zipp>=3.1.0 in ./.venv/lib/python3.9/site-packages (from importlib-resources>=3.2.0->matplotlib>=3.6.0->supervision) (3.19.2)\r\n",
      "Requirement already satisfied: six>=1.5 in ./.venv/lib/python3.9/site-packages (from python-dateutil>=2.7->matplotlib>=3.6.0->supervision) (1.16.0)\r\n",
      "Requirement already satisfied: torch in ./.venv/lib/python3.9/site-packages (2.3.1)\r\n",
      "Requirement already satisfied: filelock in ./.venv/lib/python3.9/site-packages (from torch) (3.15.4)\r\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in ./.venv/lib/python3.9/site-packages (from torch) (4.12.2)\r\n",
      "Requirement already satisfied: sympy in ./.venv/lib/python3.9/site-packages (from torch) (1.12.1)\r\n",
      "Requirement already satisfied: networkx in ./.venv/lib/python3.9/site-packages (from torch) (3.2.1)\r\n",
      "Requirement already satisfied: jinja2 in ./.venv/lib/python3.9/site-packages (from torch) (3.1.4)\r\n",
      "Requirement already satisfied: fsspec in ./.venv/lib/python3.9/site-packages (from torch) (2024.5.0)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./.venv/lib/python3.9/site-packages (from jinja2->torch) (2.1.5)\r\n",
      "Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in ./.venv/lib/python3.9/site-packages (from sympy->torch) (1.3.0)\r\n",
      "Looking in indexes: https://test.pypi.org/simple/\r\n",
      "Collecting supervision==0.3.0\r\n",
      "  Using cached https://test-files.pythonhosted.org/packages/9c/29/e30c575a94cb121417cd7725aecb6bbf78d14d923f42e0bce7cf7de9b3eb/supervision-0.3.0-py3-none-any.whl.metadata (6.4 kB)\r\n",
      "Requirement already satisfied: numpy>=1.20.0 in ./.venv/lib/python3.9/site-packages (from supervision==0.3.0) (1.26.4)\r\n",
      "INFO: pip is looking at multiple versions of supervision to determine which version is compatible with other requirements. This could take a while.\r\n",
      "\u001B[31mERROR: Could not find a version that satisfies the requirement opencv-python (from supervision) (from versions: none)\u001B[0m\u001B[31m\r\n",
      "\u001B[0m\u001B[31mERROR: No matching distribution found for opencv-python\u001B[0m\u001B[31m\r\n",
      "\u001B[0mRequirement already satisfied: pycocotools in ./.venv/lib/python3.9/site-packages (2.0.8)\r\n",
      "Requirement already satisfied: matplotlib>=2.1.0 in ./.venv/lib/python3.9/site-packages (from pycocotools) (3.9.0)\r\n",
      "Requirement already satisfied: numpy in ./.venv/lib/python3.9/site-packages (from pycocotools) (1.26.4)\r\n",
      "Requirement already satisfied: contourpy>=1.0.1 in ./.venv/lib/python3.9/site-packages (from matplotlib>=2.1.0->pycocotools) (1.2.1)\r\n",
      "Requirement already satisfied: cycler>=0.10 in ./.venv/lib/python3.9/site-packages (from matplotlib>=2.1.0->pycocotools) (0.12.1)\r\n",
      "Requirement already satisfied: fonttools>=4.22.0 in ./.venv/lib/python3.9/site-packages (from matplotlib>=2.1.0->pycocotools) (4.53.0)\r\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in ./.venv/lib/python3.9/site-packages (from matplotlib>=2.1.0->pycocotools) (1.4.5)\r\n",
      "Requirement already satisfied: packaging>=20.0 in ./.venv/lib/python3.9/site-packages (from matplotlib>=2.1.0->pycocotools) (24.1)\r\n",
      "Requirement already satisfied: pillow>=8 in ./.venv/lib/python3.9/site-packages (from matplotlib>=2.1.0->pycocotools) (10.3.0)\r\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in ./.venv/lib/python3.9/site-packages (from matplotlib>=2.1.0->pycocotools) (3.1.2)\r\n",
      "Requirement already satisfied: python-dateutil>=2.7 in ./.venv/lib/python3.9/site-packages (from matplotlib>=2.1.0->pycocotools) (2.9.0.post0)\r\n",
      "Requirement already satisfied: importlib-resources>=3.2.0 in ./.venv/lib/python3.9/site-packages (from matplotlib>=2.1.0->pycocotools) (6.4.0)\r\n",
      "Requirement already satisfied: zipp>=3.1.0 in ./.venv/lib/python3.9/site-packages (from importlib-resources>=3.2.0->matplotlib>=2.1.0->pycocotools) (3.19.2)\r\n",
      "Requirement already satisfied: six>=1.5 in ./.venv/lib/python3.9/site-packages (from python-dateutil>=2.7->matplotlib>=2.1.0->pycocotools) (1.16.0)\r\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Environment setup",
   "id": "2a7894bb6692c6af"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-27T20:41:54.942888Z",
     "start_time": "2024-06-27T20:41:53.468818Z"
    }
   },
   "cell_type": "code",
   "source": "!pip install Pypi",
   "id": "1e2ba9d338685001",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting Pypi\r\n",
      "  Downloading pypi-2.1.tar.gz (997 bytes)\r\n",
      "  Preparing metadata (setup.py) ... \u001B[?25ldone\r\n",
      "\u001B[?25hBuilding wheels for collected packages: Pypi\r\n",
      "  Building wheel for Pypi (setup.py) ... \u001B[?25ldone\r\n",
      "\u001B[?25h  Created wheel for Pypi: filename=pypi-2.1-py3-none-any.whl size=1333 sha256=07939a6ac15db6f5e3306239295adffdae807b2facacdec1a4efc7bd884d00f3\r\n",
      "  Stored in directory: /Users/clemensabraham/Library/Caches/pip/wheels/de/52/e9/d760a5e0e4b77d30df3da4e71e10451443393d77c2b3d0ed8c\r\n",
      "Successfully built Pypi\r\n",
      "Installing collected packages: Pypi\r\n",
      "Successfully installed Pypi-2.1\r\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-27T20:42:21.935806Z",
     "start_time": "2024-06-27T20:42:21.932830Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import supervision as sv\n",
    "import transformers\n",
    "import pytorch_lightning\n"
   ],
   "id": "1e21b29f89d1c899",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-27T20:55:37.190343Z",
     "start_time": "2024-06-27T20:55:36.039570Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "from transformers import DetrForObjectDetection, DetrImageProcessor\n",
    "\n",
    "# settings\n",
    "DEVICE = torch.device('mps:0' if torch.cuda.is_available() else 'cpu')\n",
    "CHECKPOINT = 'facebook/detr-resnet-50'\n",
    "CONFIDENCE_TRESHOLD = 0.5\n",
    "IOU_TRESHOLD = 0.8\n",
    "\n",
    "image_processor = DetrImageProcessor.from_pretrained(CHECKPOINT)\n",
    "model = DetrForObjectDetection.from_pretrained(CHECKPOINT)\n",
    "model.to(DEVICE)"
   ],
   "id": "9f0ccf65e7d8ae39",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at facebook/detr-resnet-50 were not used when initializing DetrForObjectDetection: ['model.backbone.conv_encoder.model.layer1.0.downsample.1.num_batches_tracked', 'model.backbone.conv_encoder.model.layer2.0.downsample.1.num_batches_tracked', 'model.backbone.conv_encoder.model.layer3.0.downsample.1.num_batches_tracked', 'model.backbone.conv_encoder.model.layer4.0.downsample.1.num_batches_tracked']\n",
      "- This IS expected if you are initializing DetrForObjectDetection from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DetrForObjectDetection from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DetrForObjectDetection(\n",
       "  (model): DetrModel(\n",
       "    (backbone): DetrConvModel(\n",
       "      (conv_encoder): DetrConvEncoder(\n",
       "        (model): FeatureListNet(\n",
       "          (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "          (bn1): DetrFrozenBatchNorm2d()\n",
       "          (act1): ReLU(inplace=True)\n",
       "          (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "          (layer1): Sequential(\n",
       "            (0): Bottleneck(\n",
       "              (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn1): DetrFrozenBatchNorm2d()\n",
       "              (act1): ReLU(inplace=True)\n",
       "              (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn2): DetrFrozenBatchNorm2d()\n",
       "              (drop_block): Identity()\n",
       "              (act2): ReLU(inplace=True)\n",
       "              (aa): Identity()\n",
       "              (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn3): DetrFrozenBatchNorm2d()\n",
       "              (act3): ReLU(inplace=True)\n",
       "              (downsample): Sequential(\n",
       "                (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (1): DetrFrozenBatchNorm2d()\n",
       "              )\n",
       "            )\n",
       "            (1): Bottleneck(\n",
       "              (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn1): DetrFrozenBatchNorm2d()\n",
       "              (act1): ReLU(inplace=True)\n",
       "              (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn2): DetrFrozenBatchNorm2d()\n",
       "              (drop_block): Identity()\n",
       "              (act2): ReLU(inplace=True)\n",
       "              (aa): Identity()\n",
       "              (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn3): DetrFrozenBatchNorm2d()\n",
       "              (act3): ReLU(inplace=True)\n",
       "            )\n",
       "            (2): Bottleneck(\n",
       "              (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn1): DetrFrozenBatchNorm2d()\n",
       "              (act1): ReLU(inplace=True)\n",
       "              (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn2): DetrFrozenBatchNorm2d()\n",
       "              (drop_block): Identity()\n",
       "              (act2): ReLU(inplace=True)\n",
       "              (aa): Identity()\n",
       "              (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn3): DetrFrozenBatchNorm2d()\n",
       "              (act3): ReLU(inplace=True)\n",
       "            )\n",
       "          )\n",
       "          (layer2): Sequential(\n",
       "            (0): Bottleneck(\n",
       "              (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn1): DetrFrozenBatchNorm2d()\n",
       "              (act1): ReLU(inplace=True)\n",
       "              (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "              (bn2): DetrFrozenBatchNorm2d()\n",
       "              (drop_block): Identity()\n",
       "              (act2): ReLU(inplace=True)\n",
       "              (aa): Identity()\n",
       "              (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn3): DetrFrozenBatchNorm2d()\n",
       "              (act3): ReLU(inplace=True)\n",
       "              (downsample): Sequential(\n",
       "                (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "                (1): DetrFrozenBatchNorm2d()\n",
       "              )\n",
       "            )\n",
       "            (1): Bottleneck(\n",
       "              (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn1): DetrFrozenBatchNorm2d()\n",
       "              (act1): ReLU(inplace=True)\n",
       "              (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn2): DetrFrozenBatchNorm2d()\n",
       "              (drop_block): Identity()\n",
       "              (act2): ReLU(inplace=True)\n",
       "              (aa): Identity()\n",
       "              (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn3): DetrFrozenBatchNorm2d()\n",
       "              (act3): ReLU(inplace=True)\n",
       "            )\n",
       "            (2): Bottleneck(\n",
       "              (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn1): DetrFrozenBatchNorm2d()\n",
       "              (act1): ReLU(inplace=True)\n",
       "              (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn2): DetrFrozenBatchNorm2d()\n",
       "              (drop_block): Identity()\n",
       "              (act2): ReLU(inplace=True)\n",
       "              (aa): Identity()\n",
       "              (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn3): DetrFrozenBatchNorm2d()\n",
       "              (act3): ReLU(inplace=True)\n",
       "            )\n",
       "            (3): Bottleneck(\n",
       "              (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn1): DetrFrozenBatchNorm2d()\n",
       "              (act1): ReLU(inplace=True)\n",
       "              (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn2): DetrFrozenBatchNorm2d()\n",
       "              (drop_block): Identity()\n",
       "              (act2): ReLU(inplace=True)\n",
       "              (aa): Identity()\n",
       "              (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn3): DetrFrozenBatchNorm2d()\n",
       "              (act3): ReLU(inplace=True)\n",
       "            )\n",
       "          )\n",
       "          (layer3): Sequential(\n",
       "            (0): Bottleneck(\n",
       "              (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn1): DetrFrozenBatchNorm2d()\n",
       "              (act1): ReLU(inplace=True)\n",
       "              (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "              (bn2): DetrFrozenBatchNorm2d()\n",
       "              (drop_block): Identity()\n",
       "              (act2): ReLU(inplace=True)\n",
       "              (aa): Identity()\n",
       "              (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn3): DetrFrozenBatchNorm2d()\n",
       "              (act3): ReLU(inplace=True)\n",
       "              (downsample): Sequential(\n",
       "                (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "                (1): DetrFrozenBatchNorm2d()\n",
       "              )\n",
       "            )\n",
       "            (1): Bottleneck(\n",
       "              (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn1): DetrFrozenBatchNorm2d()\n",
       "              (act1): ReLU(inplace=True)\n",
       "              (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn2): DetrFrozenBatchNorm2d()\n",
       "              (drop_block): Identity()\n",
       "              (act2): ReLU(inplace=True)\n",
       "              (aa): Identity()\n",
       "              (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn3): DetrFrozenBatchNorm2d()\n",
       "              (act3): ReLU(inplace=True)\n",
       "            )\n",
       "            (2): Bottleneck(\n",
       "              (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn1): DetrFrozenBatchNorm2d()\n",
       "              (act1): ReLU(inplace=True)\n",
       "              (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn2): DetrFrozenBatchNorm2d()\n",
       "              (drop_block): Identity()\n",
       "              (act2): ReLU(inplace=True)\n",
       "              (aa): Identity()\n",
       "              (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn3): DetrFrozenBatchNorm2d()\n",
       "              (act3): ReLU(inplace=True)\n",
       "            )\n",
       "            (3): Bottleneck(\n",
       "              (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn1): DetrFrozenBatchNorm2d()\n",
       "              (act1): ReLU(inplace=True)\n",
       "              (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn2): DetrFrozenBatchNorm2d()\n",
       "              (drop_block): Identity()\n",
       "              (act2): ReLU(inplace=True)\n",
       "              (aa): Identity()\n",
       "              (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn3): DetrFrozenBatchNorm2d()\n",
       "              (act3): ReLU(inplace=True)\n",
       "            )\n",
       "            (4): Bottleneck(\n",
       "              (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn1): DetrFrozenBatchNorm2d()\n",
       "              (act1): ReLU(inplace=True)\n",
       "              (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn2): DetrFrozenBatchNorm2d()\n",
       "              (drop_block): Identity()\n",
       "              (act2): ReLU(inplace=True)\n",
       "              (aa): Identity()\n",
       "              (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn3): DetrFrozenBatchNorm2d()\n",
       "              (act3): ReLU(inplace=True)\n",
       "            )\n",
       "            (5): Bottleneck(\n",
       "              (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn1): DetrFrozenBatchNorm2d()\n",
       "              (act1): ReLU(inplace=True)\n",
       "              (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn2): DetrFrozenBatchNorm2d()\n",
       "              (drop_block): Identity()\n",
       "              (act2): ReLU(inplace=True)\n",
       "              (aa): Identity()\n",
       "              (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn3): DetrFrozenBatchNorm2d()\n",
       "              (act3): ReLU(inplace=True)\n",
       "            )\n",
       "          )\n",
       "          (layer4): Sequential(\n",
       "            (0): Bottleneck(\n",
       "              (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn1): DetrFrozenBatchNorm2d()\n",
       "              (act1): ReLU(inplace=True)\n",
       "              (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "              (bn2): DetrFrozenBatchNorm2d()\n",
       "              (drop_block): Identity()\n",
       "              (act2): ReLU(inplace=True)\n",
       "              (aa): Identity()\n",
       "              (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn3): DetrFrozenBatchNorm2d()\n",
       "              (act3): ReLU(inplace=True)\n",
       "              (downsample): Sequential(\n",
       "                (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "                (1): DetrFrozenBatchNorm2d()\n",
       "              )\n",
       "            )\n",
       "            (1): Bottleneck(\n",
       "              (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn1): DetrFrozenBatchNorm2d()\n",
       "              (act1): ReLU(inplace=True)\n",
       "              (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn2): DetrFrozenBatchNorm2d()\n",
       "              (drop_block): Identity()\n",
       "              (act2): ReLU(inplace=True)\n",
       "              (aa): Identity()\n",
       "              (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn3): DetrFrozenBatchNorm2d()\n",
       "              (act3): ReLU(inplace=True)\n",
       "            )\n",
       "            (2): Bottleneck(\n",
       "              (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn1): DetrFrozenBatchNorm2d()\n",
       "              (act1): ReLU(inplace=True)\n",
       "              (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn2): DetrFrozenBatchNorm2d()\n",
       "              (drop_block): Identity()\n",
       "              (act2): ReLU(inplace=True)\n",
       "              (aa): Identity()\n",
       "              (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn3): DetrFrozenBatchNorm2d()\n",
       "              (act3): ReLU(inplace=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (position_embedding): DetrSinePositionEmbedding()\n",
       "    )\n",
       "    (input_projection): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (query_position_embeddings): Embedding(100, 256)\n",
       "    (encoder): DetrEncoder(\n",
       "      (layers): ModuleList(\n",
       "        (0-5): 6 x DetrEncoderLayer(\n",
       "          (self_attn): DetrAttention(\n",
       "            (k_proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "            (v_proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "            (q_proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "            (out_proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (activation_fn): ReLU()\n",
       "          (fc1): Linear(in_features=256, out_features=2048, bias=True)\n",
       "          (fc2): Linear(in_features=2048, out_features=256, bias=True)\n",
       "          (final_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (decoder): DetrDecoder(\n",
       "      (layers): ModuleList(\n",
       "        (0-5): 6 x DetrDecoderLayer(\n",
       "          (self_attn): DetrAttention(\n",
       "            (k_proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "            (v_proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "            (q_proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "            (out_proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "          )\n",
       "          (activation_fn): ReLU()\n",
       "          (self_attn_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (encoder_attn): DetrAttention(\n",
       "            (k_proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "            (v_proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "            (q_proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "            (out_proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "          )\n",
       "          (encoder_attn_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=256, out_features=2048, bias=True)\n",
       "          (fc2): Linear(in_features=2048, out_features=256, bias=True)\n",
       "          (final_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "      (layernorm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "  )\n",
       "  (class_labels_classifier): Linear(in_features=256, out_features=92, bias=True)\n",
       "  (bbox_predictor): DetrMLPPredictionHead(\n",
       "    (layers): ModuleList(\n",
       "      (0-1): 2 x Linear(in_features=256, out_features=256, bias=True)\n",
       "      (2): Linear(in_features=256, out_features=4, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-28T05:07:11.619052Z",
     "start_time": "2024-06-28T05:07:11.609827Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "import torchvision\n",
    "\n",
    "dataset_location = \"/Users/clemensabraham/PycharmProjects/wildwatchai/outputlnw0.12/PhillipWildAnimals.v1i.coco\"\n",
    "\n",
    "# settings\n",
    "ANNOTATION_FILE_NAME = \"_annotations.coco.json\"\n",
    "TRAIN_DIRECTORY = os.path.join(dataset_location, \"train\")\n",
    "\n",
    "\n",
    "class CocoDetection(torchvision.datasets.CocoDetection):\n",
    "    def __init__(\n",
    "            self,\n",
    "            image_directory_path: str,\n",
    "            image_processor,\n",
    "            train: bool = True\n",
    "    ):\n",
    "        annotation_file_path = os.path.join(image_directory_path, ANNOTATION_FILE_NAME)\n",
    "        super(CocoDetection, self).__init__(image_directory_path, annotation_file_path)\n",
    "        self.image_processor = image_processor\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        images, annotations = super(CocoDetection, self).__getitem__(idx)\n",
    "        image_id = self.ids[idx]\n",
    "        annotations = {'image_id': image_id, 'annotations': annotations}\n",
    "        encoding = self.image_processor(images=images, annotations=annotations, return_tensors=\"pt\")\n",
    "        pixel_values = encoding[\"pixel_values\"].squeeze()\n",
    "        target = encoding[\"labels\"][0]\n",
    "\n",
    "        return pixel_values, target\n",
    "\n",
    "\n",
    "\n",
    "TRAIN_DATASET = CocoDetection(\n",
    "    image_directory_path=TRAIN_DIRECTORY,\n",
    "    image_processor=image_processor,\n",
    "    train=True)\n",
    "\"\"\"VAL_DATASET = CocoDetection(\n",
    "    image_directory_path=VAL_DIRECTORY,\n",
    "    image_processor=image_processor,\n",
    "    train=False)\n",
    "TEST_DATASET = CocoDetection(\n",
    "    image_directory_path=TEST_DIRECTORY,\n",
    "    image_processor=image_processor,\n",
    "    train=False)\n",
    "\"\"\"\n",
    "print(\"Number of training examples:\", len(TRAIN_DATASET))\n",
    "\"\"\"print(\"Number of validation examples:\", len(VAL_DATASET))\n",
    "print(\"Number of test examples:\", len(TEST_DATASET))\"\"\"\n"
   ],
   "id": "da45e7c0b3f155c6",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Number of training examples: 310\n"
     ]
    }
   ],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-28T05:06:48.323872Z",
     "start_time": "2024-06-28T05:06:48.265229Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import random\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# select random image\n",
    "image_ids = TRAIN_DATASET.coco.getImgIds()\n",
    "image_id = random.choice(image_ids)\n",
    "print('Image #{}'.format(image_id))\n",
    "\n",
    "# load image and annotatons\n",
    "image = TRAIN_DATASET.coco.loadImgs(image_id)[1]\n",
    "annotations = TRAIN_DATASET.coco.imgToAnns[image_id]\n",
    "image_path = os.path.join(TRAIN_DATASET.root, image['file_name'])\n",
    "image = cv2.imread(image_path)\n",
    "\n",
    "# annotate\n",
    "detections = sv.Detections.from_coco_annotations(coco_annotation=annotations)\n",
    "\n",
    "# we will use id2label function for training\n",
    "categories = TRAIN_DATASET.coco.cats\n",
    "id2label = {k: v['name'] for k,v in categories.items()}\n",
    "\n",
    "labels = [\n",
    "    f\"{id2label[class_id]}\"\n",
    "    for _, _, class_id, _\n",
    "    in detections\n",
    "]\n",
    "\n",
    "box_annotator = sv.BoxAnnotator()\n",
    "frame = box_annotator.annotate(scene=image, detections=detections, labels=labels)\n",
    "\n",
    "%matplotlib inline\n",
    "sv.show_frame_in_notebook(image, (8, 8))"
   ],
   "id": "64784b0cd0cd39e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image #144\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mIndexError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[19], line 12\u001B[0m\n\u001B[1;32m      9\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mImage #\u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m'\u001B[39m\u001B[38;5;241m.\u001B[39mformat(image_id))\n\u001B[1;32m     11\u001B[0m \u001B[38;5;66;03m# load image and annotatons\u001B[39;00m\n\u001B[0;32m---> 12\u001B[0m image \u001B[38;5;241m=\u001B[39m \u001B[43mTRAIN_DATASET\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcoco\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mloadImgs\u001B[49m\u001B[43m(\u001B[49m\u001B[43mimage_id\u001B[49m\u001B[43m)\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m]\u001B[49m\n\u001B[1;32m     13\u001B[0m annotations \u001B[38;5;241m=\u001B[39m TRAIN_DATASET\u001B[38;5;241m.\u001B[39mcoco\u001B[38;5;241m.\u001B[39mimgToAnns[image_id]\n\u001B[1;32m     14\u001B[0m image_path \u001B[38;5;241m=\u001B[39m os\u001B[38;5;241m.\u001B[39mpath\u001B[38;5;241m.\u001B[39mjoin(TRAIN_DATASET\u001B[38;5;241m.\u001B[39mroot, image[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mfile_name\u001B[39m\u001B[38;5;124m'\u001B[39m])\n",
      "\u001B[0;31mIndexError\u001B[0m: list index out of range"
     ]
    }
   ],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-28T05:09:01.603416Z",
     "start_time": "2024-06-28T05:09:01.598953Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "def collate_fn(batch):\n",
    "    # DETR authors employ various image sizes during training, making it not possible \n",
    "    # to directly batch together images. Hence they pad the images to the biggest \n",
    "    # resolution in a given batch, and create a corresponding binary pixel_mask \n",
    "    # which indicates which pixels are real/which are padding\n",
    "    pixel_values = [item[0] for item in batch]\n",
    "    encoding = image_processor.pad(pixel_values, return_tensors=\"pt\")\n",
    "    labels = [item[1] for item in batch]\n",
    "    return {\n",
    "        'pixel_values': encoding['pixel_values'],\n",
    "        'pixel_mask': encoding['pixel_mask'],\n",
    "        'labels': labels\n",
    "    }\n",
    "\n",
    "TRAIN_DATALOADER = DataLoader(dataset=TRAIN_DATASET, collate_fn=collate_fn, batch_size=16, shuffle=True)\n",
    "##VAL_DATALOADER = DataLoader(dataset=VAL_DATASET, collate_fn=collate_fn, batch_size=16)\n",
    "##TEST_DATALOADER = DataLoader(dataset=TEST_DATASET, collate_fn=collate_fn, batch_size=16)\n"
   ],
   "id": "ae2052e648f0c220",
   "outputs": [],
   "execution_count": 22
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Train model with PyTorch Lightning: defining a regular PyTorch dataset. Each item of the dataset is an image and corresponding annotations. Torchvision already provides a CocoDetection dataset, which we can use. We only add a feature extractor (DetrImageProcessor) to resize + normalize the images, and to turn the annotations (which are in COCO format) in the format that DETR expects. It will also resize the annotations accordingly.",
   "id": "7775c94e5fc78e5"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-28T05:18:18.094581Z",
     "start_time": "2024-06-28T05:18:18.070367Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pytorch_lightning as pl\n",
    "from transformers import DetrForObjectDetection\n",
    "import torch\n",
    "\n",
    "\n",
    "class Detr(pl.LightningModule):\n",
    "\n",
    "    def __init__(self, lr, lr_backbone, weight_decay):\n",
    "        super().__init__()\n",
    "        self.model = DetrForObjectDetection.from_pretrained(\n",
    "            pretrained_model_name_or_path=CHECKPOINT,\n",
    "            num_labels=len(id2label),\n",
    "            ignore_mismatched_sizes=True\n",
    "        )\n",
    "\n",
    "        self.lr = lr\n",
    "        self.lr_backbone = lr_backbone\n",
    "        self.weight_decay = weight_decay\n",
    "\n",
    "    def forward(self, pixel_values, pixel_mask):\n",
    "        return self.model(pixel_values=pixel_values, pixel_mask=pixel_mask)\n",
    "\n",
    "    def common_step(self, batch, batch_idx):\n",
    "        pixel_values = batch[\"pixel_values\"]\n",
    "        pixel_mask = batch[\"pixel_mask\"]\n",
    "        labels = [{k: v.to(self.device) for k, v in t.items()} for t in batch[\"labels\"]]\n",
    "\n",
    "        outputs = self.model(pixel_values=pixel_values, pixel_mask=pixel_mask, labels=labels)\n",
    "\n",
    "        loss = outputs.loss\n",
    "        loss_dict = outputs.loss_dict\n",
    "\n",
    "        return loss, loss_dict\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        loss, loss_dict = self.common_step(batch, batch_idx)\n",
    "        # logs metrics for each training_step, and the average across the epoch\n",
    "        self.log(\"training_loss\", loss)\n",
    "        for k,v in loss_dict.items():\n",
    "            self.log(\"train_\" + k, v.item())\n",
    "\n",
    "        return loss\n",
    "\n",
    "   \"\"\"def validation_step(self, batch, batch_idx):\n",
    "        loss, loss_dict = self.common_step(batch, batch_idx)\n",
    "        self.log(\"validation/loss\", loss)\n",
    "        for k, v in loss_dict.items():\n",
    "            self.log(\"validation_\" + k, v.item())\n",
    "\n",
    "        return loss\n",
    "    \"\"\"\n",
    "    def configure_optimizers(self):\n",
    "        # DETR authors decided to use different learning rate for backbone\n",
    "        # you can learn more about it here:\n",
    "        # - https://github.com/facebookresearch/detr/blob/3af9fa878e73b6894ce3596450a8d9b89d918ca9/main.py#L22-L23\n",
    "        # - https://github.com/facebookresearch/detr/blob/3af9fa878e73b6894ce3596450a8d9b89d918ca9/main.py#L131-L139\n",
    "        param_dicts = [\n",
    "            {\n",
    "                \"params\": [p for n, p in self.named_parameters() if \"backbone\" not in n and p.requires_grad]},\n",
    "            {\n",
    "                \"params\": [p for n, p in self.named_parameters() if \"backbone\" in n and p.requires_grad],\n",
    "                \"lr\": self.lr_backbone,\n",
    "            },\n",
    "        ]\n",
    "        return torch.optim.AdamW(param_dicts, lr=self.lr, weight_decay=self.weight_decay)\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return TRAIN_DATALOADER\n",
    "\n",
    "    \"\"\"def val_dataloader(self):\n",
    "        return VAL_DATALOADER\"\"\""
   ],
   "id": "a24f7adab4faab26",
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unindent does not match any outer indentation level (<tokenize>, line 44)",
     "output_type": "error",
     "traceback": [
      "\u001B[0;36m  File \u001B[0;32m<tokenize>:44\u001B[0;36m\u001B[0m\n\u001B[0;31m    \"\"\"def validation_step(self, batch, batch_idx):\u001B[0m\n\u001B[0m    ^\u001B[0m\n\u001B[0;31mIndentationError\u001B[0m\u001B[0;31m:\u001B[0m unindent does not match any outer indentation level\n"
     ]
    }
   ],
   "execution_count": 26
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-28T05:19:31.674969Z",
     "start_time": "2024-06-28T05:19:31.667460Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model = Detr(lr=1e-4, lr_backbone=1e-5, weight_decay=1e-4)\n",
    "\n",
    "batch = next(iter(TRAIN_DATALOADER))\n",
    "outputs = model(pixel_values=batch['pixel_values'], pixel_mask=batch['pixel_mask']"
   ],
   "id": "98e6cfb2d24deab9",
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unexpected EOF while parsing (1103201245.py, line 4)",
     "output_type": "error",
     "traceback": [
      "\u001B[0;36m  Cell \u001B[0;32mIn[27], line 4\u001B[0;36m\u001B[0m\n\u001B[0;31m    outputs = model(pixel_values=batch['pixel_values'], pixel_mask=batch['pixel_mask']\u001B[0m\n\u001B[0m                                                                                      ^\u001B[0m\n\u001B[0;31mSyntaxError\u001B[0m\u001B[0;31m:\u001B[0m unexpected EOF while parsing\n"
     ]
    }
   ],
   "execution_count": 27
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Adjust Training Epochs",
   "id": "1cf1afbebb9c14e3"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-28T05:26:01.877025Z",
     "start_time": "2024-06-28T05:26:01.111540Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from pytorch_lightning import Trainer\n",
    "!pip install tensorboardX\n",
    "\n",
    "# settings\n",
    "MAX_EPOCHS = 40\n",
    "\n",
    "# pytorch_lightning < 2.0.0\n",
    "# trainer = Trainer(gpus=1, max_epochs=MAX_EPOCHS, gradient_clip_val=0.1, accumulate_grad_batches=8, log_every_n_steps=5)\n",
    "\n",
    "# pytorch_lightning >= 2.0.0\n",
    "trainer = Trainer(devices=1, accelerator=\"gpu\", max_epochs=MAX_EPOCHS, gradient_clip_val=0.1, accumulate_grad_batches=8, log_every_n_steps=5)\n",
    "\n",
    "trainer.fit(model)\n"
   ],
   "id": "c4beb6986bf17a80",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorboardX in ./.venv/lib/python3.9/site-packages (2.6.2.2)\r\n",
      "Requirement already satisfied: numpy in ./.venv/lib/python3.9/site-packages (from tensorboardX) (1.26.4)\r\n",
      "Requirement already satisfied: packaging in ./.venv/lib/python3.9/site-packages (from tensorboardX) (24.1)\r\n",
      "Requirement already satisfied: protobuf>=3.20 in ./.venv/lib/python3.9/site-packages (from tensorboardX) (4.25.3)\r\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "`model` must be a `LightningModule` or `torch._dynamo.OptimizedModule`, got `DetrForObjectDetection`",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[29], line 13\u001B[0m\n\u001B[1;32m      7\u001B[0m \u001B[38;5;66;03m# pytorch_lightning < 2.0.0\u001B[39;00m\n\u001B[1;32m      8\u001B[0m \u001B[38;5;66;03m# trainer = Trainer(gpus=1, max_epochs=MAX_EPOCHS, gradient_clip_val=0.1, accumulate_grad_batches=8, log_every_n_steps=5)\u001B[39;00m\n\u001B[1;32m      9\u001B[0m \n\u001B[1;32m     10\u001B[0m \u001B[38;5;66;03m# pytorch_lightning >= 2.0.0\u001B[39;00m\n\u001B[1;32m     11\u001B[0m trainer \u001B[38;5;241m=\u001B[39m Trainer(devices\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m, accelerator\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mgpu\u001B[39m\u001B[38;5;124m\"\u001B[39m, max_epochs\u001B[38;5;241m=\u001B[39mMAX_EPOCHS, gradient_clip_val\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0.1\u001B[39m, accumulate_grad_batches\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m8\u001B[39m, log_every_n_steps\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m5\u001B[39m)\n\u001B[0;32m---> 13\u001B[0m \u001B[43mtrainer\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/PycharmProjects/accelerate/.venv/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py:537\u001B[0m, in \u001B[0;36mTrainer.fit\u001B[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001B[0m\n\u001B[1;32m    503\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mfit\u001B[39m(\n\u001B[1;32m    504\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[1;32m    505\u001B[0m     model: \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mpl.LightningModule\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    509\u001B[0m     ckpt_path: Optional[_PATH] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[1;32m    510\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    511\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124mr\u001B[39m\u001B[38;5;124;03m\"\"\"Runs the full optimization routine.\u001B[39;00m\n\u001B[1;32m    512\u001B[0m \n\u001B[1;32m    513\u001B[0m \u001B[38;5;124;03m    Args:\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    535\u001B[0m \n\u001B[1;32m    536\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m--> 537\u001B[0m     model \u001B[38;5;241m=\u001B[39m \u001B[43m_maybe_unwrap_optimized\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    538\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstrategy\u001B[38;5;241m.\u001B[39m_lightning_module \u001B[38;5;241m=\u001B[39m model\n\u001B[1;32m    539\u001B[0m     _verify_strategy_supports_compile(model, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstrategy)\n",
      "File \u001B[0;32m~/PycharmProjects/accelerate/.venv/lib/python3.9/site-packages/pytorch_lightning/utilities/compile.py:116\u001B[0m, in \u001B[0;36m_maybe_unwrap_optimized\u001B[0;34m(model)\u001B[0m\n\u001B[1;32m    114\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m model\n\u001B[1;32m    115\u001B[0m _check_mixed_imports(model)\n\u001B[0;32m--> 116\u001B[0m \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m(\n\u001B[1;32m    117\u001B[0m     \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m`model` must be a `LightningModule` or `torch._dynamo.OptimizedModule`, got `\u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mtype\u001B[39m(model)\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__qualname__\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m`\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    118\u001B[0m )\n",
      "\u001B[0;31mTypeError\u001B[0m: `model` must be a `LightningModule` or `torch._dynamo.OptimizedModule`, got `DetrForObjectDetection`"
     ]
    }
   ],
   "execution_count": 29
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-28T05:27:35.620250Z",
     "start_time": "2024-06-28T05:27:35.605085Z"
    }
   },
   "cell_type": "code",
   "source": "model.to(DEVICE)",
   "id": "1da8254d42b7fc86",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DetrForObjectDetection(\n",
       "  (model): DetrModel(\n",
       "    (backbone): DetrConvModel(\n",
       "      (conv_encoder): DetrConvEncoder(\n",
       "        (model): FeatureListNet(\n",
       "          (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "          (bn1): DetrFrozenBatchNorm2d()\n",
       "          (act1): ReLU(inplace=True)\n",
       "          (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "          (layer1): Sequential(\n",
       "            (0): Bottleneck(\n",
       "              (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn1): DetrFrozenBatchNorm2d()\n",
       "              (act1): ReLU(inplace=True)\n",
       "              (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn2): DetrFrozenBatchNorm2d()\n",
       "              (drop_block): Identity()\n",
       "              (act2): ReLU(inplace=True)\n",
       "              (aa): Identity()\n",
       "              (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn3): DetrFrozenBatchNorm2d()\n",
       "              (act3): ReLU(inplace=True)\n",
       "              (downsample): Sequential(\n",
       "                (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (1): DetrFrozenBatchNorm2d()\n",
       "              )\n",
       "            )\n",
       "            (1): Bottleneck(\n",
       "              (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn1): DetrFrozenBatchNorm2d()\n",
       "              (act1): ReLU(inplace=True)\n",
       "              (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn2): DetrFrozenBatchNorm2d()\n",
       "              (drop_block): Identity()\n",
       "              (act2): ReLU(inplace=True)\n",
       "              (aa): Identity()\n",
       "              (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn3): DetrFrozenBatchNorm2d()\n",
       "              (act3): ReLU(inplace=True)\n",
       "            )\n",
       "            (2): Bottleneck(\n",
       "              (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn1): DetrFrozenBatchNorm2d()\n",
       "              (act1): ReLU(inplace=True)\n",
       "              (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn2): DetrFrozenBatchNorm2d()\n",
       "              (drop_block): Identity()\n",
       "              (act2): ReLU(inplace=True)\n",
       "              (aa): Identity()\n",
       "              (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn3): DetrFrozenBatchNorm2d()\n",
       "              (act3): ReLU(inplace=True)\n",
       "            )\n",
       "          )\n",
       "          (layer2): Sequential(\n",
       "            (0): Bottleneck(\n",
       "              (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn1): DetrFrozenBatchNorm2d()\n",
       "              (act1): ReLU(inplace=True)\n",
       "              (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "              (bn2): DetrFrozenBatchNorm2d()\n",
       "              (drop_block): Identity()\n",
       "              (act2): ReLU(inplace=True)\n",
       "              (aa): Identity()\n",
       "              (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn3): DetrFrozenBatchNorm2d()\n",
       "              (act3): ReLU(inplace=True)\n",
       "              (downsample): Sequential(\n",
       "                (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "                (1): DetrFrozenBatchNorm2d()\n",
       "              )\n",
       "            )\n",
       "            (1): Bottleneck(\n",
       "              (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn1): DetrFrozenBatchNorm2d()\n",
       "              (act1): ReLU(inplace=True)\n",
       "              (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn2): DetrFrozenBatchNorm2d()\n",
       "              (drop_block): Identity()\n",
       "              (act2): ReLU(inplace=True)\n",
       "              (aa): Identity()\n",
       "              (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn3): DetrFrozenBatchNorm2d()\n",
       "              (act3): ReLU(inplace=True)\n",
       "            )\n",
       "            (2): Bottleneck(\n",
       "              (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn1): DetrFrozenBatchNorm2d()\n",
       "              (act1): ReLU(inplace=True)\n",
       "              (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn2): DetrFrozenBatchNorm2d()\n",
       "              (drop_block): Identity()\n",
       "              (act2): ReLU(inplace=True)\n",
       "              (aa): Identity()\n",
       "              (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn3): DetrFrozenBatchNorm2d()\n",
       "              (act3): ReLU(inplace=True)\n",
       "            )\n",
       "            (3): Bottleneck(\n",
       "              (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn1): DetrFrozenBatchNorm2d()\n",
       "              (act1): ReLU(inplace=True)\n",
       "              (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn2): DetrFrozenBatchNorm2d()\n",
       "              (drop_block): Identity()\n",
       "              (act2): ReLU(inplace=True)\n",
       "              (aa): Identity()\n",
       "              (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn3): DetrFrozenBatchNorm2d()\n",
       "              (act3): ReLU(inplace=True)\n",
       "            )\n",
       "          )\n",
       "          (layer3): Sequential(\n",
       "            (0): Bottleneck(\n",
       "              (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn1): DetrFrozenBatchNorm2d()\n",
       "              (act1): ReLU(inplace=True)\n",
       "              (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "              (bn2): DetrFrozenBatchNorm2d()\n",
       "              (drop_block): Identity()\n",
       "              (act2): ReLU(inplace=True)\n",
       "              (aa): Identity()\n",
       "              (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn3): DetrFrozenBatchNorm2d()\n",
       "              (act3): ReLU(inplace=True)\n",
       "              (downsample): Sequential(\n",
       "                (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "                (1): DetrFrozenBatchNorm2d()\n",
       "              )\n",
       "            )\n",
       "            (1): Bottleneck(\n",
       "              (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn1): DetrFrozenBatchNorm2d()\n",
       "              (act1): ReLU(inplace=True)\n",
       "              (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn2): DetrFrozenBatchNorm2d()\n",
       "              (drop_block): Identity()\n",
       "              (act2): ReLU(inplace=True)\n",
       "              (aa): Identity()\n",
       "              (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn3): DetrFrozenBatchNorm2d()\n",
       "              (act3): ReLU(inplace=True)\n",
       "            )\n",
       "            (2): Bottleneck(\n",
       "              (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn1): DetrFrozenBatchNorm2d()\n",
       "              (act1): ReLU(inplace=True)\n",
       "              (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn2): DetrFrozenBatchNorm2d()\n",
       "              (drop_block): Identity()\n",
       "              (act2): ReLU(inplace=True)\n",
       "              (aa): Identity()\n",
       "              (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn3): DetrFrozenBatchNorm2d()\n",
       "              (act3): ReLU(inplace=True)\n",
       "            )\n",
       "            (3): Bottleneck(\n",
       "              (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn1): DetrFrozenBatchNorm2d()\n",
       "              (act1): ReLU(inplace=True)\n",
       "              (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn2): DetrFrozenBatchNorm2d()\n",
       "              (drop_block): Identity()\n",
       "              (act2): ReLU(inplace=True)\n",
       "              (aa): Identity()\n",
       "              (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn3): DetrFrozenBatchNorm2d()\n",
       "              (act3): ReLU(inplace=True)\n",
       "            )\n",
       "            (4): Bottleneck(\n",
       "              (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn1): DetrFrozenBatchNorm2d()\n",
       "              (act1): ReLU(inplace=True)\n",
       "              (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn2): DetrFrozenBatchNorm2d()\n",
       "              (drop_block): Identity()\n",
       "              (act2): ReLU(inplace=True)\n",
       "              (aa): Identity()\n",
       "              (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn3): DetrFrozenBatchNorm2d()\n",
       "              (act3): ReLU(inplace=True)\n",
       "            )\n",
       "            (5): Bottleneck(\n",
       "              (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn1): DetrFrozenBatchNorm2d()\n",
       "              (act1): ReLU(inplace=True)\n",
       "              (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn2): DetrFrozenBatchNorm2d()\n",
       "              (drop_block): Identity()\n",
       "              (act2): ReLU(inplace=True)\n",
       "              (aa): Identity()\n",
       "              (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn3): DetrFrozenBatchNorm2d()\n",
       "              (act3): ReLU(inplace=True)\n",
       "            )\n",
       "          )\n",
       "          (layer4): Sequential(\n",
       "            (0): Bottleneck(\n",
       "              (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn1): DetrFrozenBatchNorm2d()\n",
       "              (act1): ReLU(inplace=True)\n",
       "              (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "              (bn2): DetrFrozenBatchNorm2d()\n",
       "              (drop_block): Identity()\n",
       "              (act2): ReLU(inplace=True)\n",
       "              (aa): Identity()\n",
       "              (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn3): DetrFrozenBatchNorm2d()\n",
       "              (act3): ReLU(inplace=True)\n",
       "              (downsample): Sequential(\n",
       "                (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "                (1): DetrFrozenBatchNorm2d()\n",
       "              )\n",
       "            )\n",
       "            (1): Bottleneck(\n",
       "              (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn1): DetrFrozenBatchNorm2d()\n",
       "              (act1): ReLU(inplace=True)\n",
       "              (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn2): DetrFrozenBatchNorm2d()\n",
       "              (drop_block): Identity()\n",
       "              (act2): ReLU(inplace=True)\n",
       "              (aa): Identity()\n",
       "              (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn3): DetrFrozenBatchNorm2d()\n",
       "              (act3): ReLU(inplace=True)\n",
       "            )\n",
       "            (2): Bottleneck(\n",
       "              (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn1): DetrFrozenBatchNorm2d()\n",
       "              (act1): ReLU(inplace=True)\n",
       "              (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn2): DetrFrozenBatchNorm2d()\n",
       "              (drop_block): Identity()\n",
       "              (act2): ReLU(inplace=True)\n",
       "              (aa): Identity()\n",
       "              (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn3): DetrFrozenBatchNorm2d()\n",
       "              (act3): ReLU(inplace=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (position_embedding): DetrSinePositionEmbedding()\n",
       "    )\n",
       "    (input_projection): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (query_position_embeddings): Embedding(100, 256)\n",
       "    (encoder): DetrEncoder(\n",
       "      (layers): ModuleList(\n",
       "        (0-5): 6 x DetrEncoderLayer(\n",
       "          (self_attn): DetrAttention(\n",
       "            (k_proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "            (v_proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "            (q_proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "            (out_proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (activation_fn): ReLU()\n",
       "          (fc1): Linear(in_features=256, out_features=2048, bias=True)\n",
       "          (fc2): Linear(in_features=2048, out_features=256, bias=True)\n",
       "          (final_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (decoder): DetrDecoder(\n",
       "      (layers): ModuleList(\n",
       "        (0-5): 6 x DetrDecoderLayer(\n",
       "          (self_attn): DetrAttention(\n",
       "            (k_proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "            (v_proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "            (q_proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "            (out_proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "          )\n",
       "          (activation_fn): ReLU()\n",
       "          (self_attn_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (encoder_attn): DetrAttention(\n",
       "            (k_proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "            (v_proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "            (q_proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "            (out_proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "          )\n",
       "          (encoder_attn_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=256, out_features=2048, bias=True)\n",
       "          (fc2): Linear(in_features=2048, out_features=256, bias=True)\n",
       "          (final_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "      (layernorm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "  )\n",
       "  (class_labels_classifier): Linear(in_features=256, out_features=92, bias=True)\n",
       "  (bbox_predictor): DetrMLPPredictionHead(\n",
       "    (layers): ModuleList(\n",
       "      (0-1): 2 x Linear(in_features=256, out_features=256, bias=True)\n",
       "      (2): Linear(in_features=256, out_features=4, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 30
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "\n",
    "Inference on test set\n"
   ],
   "id": "b016256dd73f0c14"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import random\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# utils\n",
    "categories = TEST_DATASET.coco.cats\n",
    "id2label = {k: v['name'] for k,v in categories.items()}\n",
    "box_annotator = sv.BoxAnnotator()\n",
    "\n",
    "# select random image\n",
    "image_ids = TEST_DATASET.coco.getImgIds()\n",
    "image_id = random.choice(image_ids)\n",
    "print('Image #{}'.format(image_id))\n",
    "\n",
    "# load image and annotatons \n",
    "image = TEST_DATASET.coco.loadImgs(image_id)[0]\n",
    "annotations = TEST_DATASET.coco.imgToAnns[image_id]\n",
    "image_path = os.path.join(TEST_DATASET.root, image['file_name'])\n",
    "image = cv2.imread(image_path)\n",
    "\n",
    "# annotate\n",
    "detections = sv.Detections.from_coco_annotations(coco_annotation=annotations)\n",
    "labels = [f\"{id2label[class_id]}\" for _, _, class_id, _ in detections]\n",
    "frame = box_annotator.annotate(scene=image.copy(), detections=detections, labels=labels)\n",
    "\n",
    "print('ground truth')\n",
    "%matplotlib inline\n",
    "sv.show_frame_in_notebook(frame, (16, 16))\n",
    "\n",
    "# inference\n",
    "with torch.no_grad():\n",
    "\n",
    "# load image and predict\n",
    "inputs = image_processor(images=image, return_tensors='pt').to(DEVICE)\n",
    "outputs = model(**inputs)\n",
    "\n",
    "# post-process\n",
    "target_sizes = torch.tensor([image.shape[:2]]).to(DEVICE)\n",
    "results = image_processor.post_process_object_detection(\n",
    "outputs=outputs,\n",
    "threshold=CONFIDENCE_TRESHOLD,\n",
    "target_sizes=target_sizes\n",
    ")[0]\n",
    "\n",
    "# annotate\n",
    "detections = sv.Detections.from_transformers(transformers_results=results).with_nms(threshold=0.5)\n",
    "labels = [f\"{id2label[class_id]} {confidence:.2f}\" for _, confidence, class_id, _ in detections]\n",
    "frame = box_annotator.annotate(scene=image.copy(), detections=detections, labels=labels)\n",
    "\n",
    "print('detections')\n",
    "%matplotlib inline\n",
    "sv.show_frame_in_notebook(frame, (16, 16))"
   ],
   "id": "75301e9660ba33fe"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Evaluation",
   "id": "a246618783d3c9d4"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "!pip install -q coco_eval",
   "id": "a418d75a61dfbcf5"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def convert_to_xywh(boxes):\n",
    "    xmin, ymin, xmax, ymax = boxes.unbind(1)\n",
    "    return torch.stack((xmin, ymin, xmax - xmin, ymax - ymin), dim=1)\n",
    "\n",
    "def prepare_for_coco_detection(predictions):\n",
    "    coco_results = []\n",
    "    for original_id, prediction in predictions.items():\n",
    "        if len(prediction) == 0:\n",
    "            continue\n",
    "\n",
    "        boxes = prediction[\"boxes\"]\n",
    "        boxes = convert_to_xywh(boxes).tolist()\n",
    "        scores = prediction[\"scores\"].tolist()\n",
    "        labels = prediction[\"labels\"].tolist()\n",
    "\n",
    "        coco_results.extend(\n",
    "            [\n",
    "                {\n",
    "                    \"image_id\": original_id,\n",
    "                    \"category_id\": labels[k],\n",
    "                    \"bbox\": box,\n",
    "                    \"score\": scores[k],\n",
    "                }\n",
    "                for k, box in enumerate(boxes)\n",
    "            ]\n",
    "        )\n",
    "    return coco_results\n"
   ],
   "id": "caa697d4a1ddbbb2"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from coco_eval import CocoEvaluator\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "evaluator = CocoEvaluator(coco_gt=TEST_DATASET.coco, iou_types=[\"bbox\"])\n",
    "\n",
    "print(\"Running evaluation...\")\n",
    "\n",
    "for idx, batch in enumerate(tqdm(TEST_DATALOADER)):\n",
    "    pixel_values = batch[\"pixel_values\"].to(DEVICE)\n",
    "    pixel_mask = batch[\"pixel_mask\"].to(DEVICE)\n",
    "    labels = [{k: v.to(DEVICE) for k, v in t.items()} for t in batch[\"labels\"]]\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model(pixel_values=pixel_values, pixel_mask=pixel_mask)\n",
    "\n",
    "    orig_target_sizes = torch.stack([target[\"orig_size\"] for target in labels], dim=0)\n",
    "    results = image_processor.post_process_object_detection(outputs, target_sizes=orig_target_sizes)\n",
    "\n",
    "    predictions = {target['image_id'].item(): output for target, output in zip(labels, results)}\n",
    "    predictions = prepare_for_coco_detection(predictions)\n",
    "    evaluator.update(predictions)\n",
    "\n",
    "evaluator.synchronize_between_processes()\n",
    "evaluator.accumulate()\n",
    "evaluator.summarize()"
   ],
   "id": "a1ceefcbaeee92ee"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Save and Load Model",
   "id": "93f314a7dca6f003"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "## Save and load model\n",
    "\n",
    "MODEL_PATH = '/kaggle/working/DETR_finetuned'\n",
    "\n",
    "model.model.save_pretrained(MODEL_PATH)"
   ],
   "id": "93e49cf22cf71c82"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# model = DetrForObjectDetection.from_pretrained(MODEL_PATH)\n",
    "# model.to(DEVICE)"
   ],
   "id": "9d62645193cfbd17"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
